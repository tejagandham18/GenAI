# ğŸ§  RAG â€” Pipeline Summary (By Code File)

This document summarizes each stage of the RAG system and explains what process is performed by each corresponding Python file.

---

## ğŸ“‚ 1. `ingestion_pipeline.py` â€” Document Preparation

**Purpose:**  
Prepare documents for retrieval by converting them into embeddings and storing them in a vector database.

**Main Processes:**
- Load raw `.txt` documents
- Split documents into smaller chunks
- Convert chunks to embeddings
- Store embeddings + metadata into Chroma DB
- Persist DB to disk for reuse

**Resulting Output:**
```
Documents â†’ Chunks â†’ Embeddings â†’ Vector Store
```

---

## ğŸ“‚ 2. `retrieval_pipeline.py` â€” Context Retrieval

**Purpose:**  
Search Vector DB for document chunks related to a given user query.

**Main Processes:**
- Load persisted Chroma DB
- Embed the user query
- Perform similarity search
- Return relevant chunks as context

**Resulting Output:**
```
User Query â†’ Relevant Chunks (Context)
```

---

## ğŸ“‚ 3. `answer_generation.py` â€” Final Answer Construction

**Purpose:**  
Generate an answer using retrieved chunks as factual context.

**Main Processes:**
- Retrieve relevant chunks
- Inject chunks into the LLM prompt
- Instruct LLM to answer using provided context only
- Apply hallucination guardrails

**Resulting Output:**
```
Context + Query â†’ LLM Answer (Grounded)
```

---

## ğŸ“‚ 4. `chat_pipeline.py` â€” Conversational RAG with Memory

**Purpose:**  
Support multi-turn chat and handle follow-up questions.

**Main Processes:**
- Maintain conversation history
- Rewrite follow-up questions into standalone queries
- Retrieve context again for rewritten query
- Generate grounded answer
- Store Q&A into memory

**Resulting Output:**
```
Dialogue â†’ Rewrite â†’ Retrieve â†’ Answer â†’ Memory
```

---

## ğŸ“‚ 5. `chunking_methods.py` â€” Character-Based Chunking

**Purpose:**  
Split documents by size or simple structural rules.

**Main Processes:**
- Use fixed chunk size limits
- Split using separators such as space or newline

**Output:**
```
Text â†’ Mechanical Chunks (size-based)
```

---

## ğŸ“‚ 6. `semantic_chunking.py` â€” Meaning-Based Chunking

**Purpose:**  
Split text based on semantic similarity between sentences.

**Main Processes:**
- Embed sentences
- Measure sentence similarity
- Detect topic shifts (breakpoints)
- Group related sentences together

**Output:**
```
Text â†’ Topic-Coherent Chunks
```

---

## ğŸ“‚ 7. `agentic_chunking.py` â€” LLM-Decided Chunking

**Purpose:**  
Allow LLM to split text at natural human topics.

**Main Processes:**
- Prompt LLM with chunking rules
- LLM inserts split markers
- Parser converts into final chunks

**Output:**
```
Text â†’ Human-Like Chunks (LLM Reasoned)
```

---

## ğŸ“‚ 8. `multi_query_retrieval.py` â€” Multi-Query Expansion

**Purpose:**  
Increase retrieval recall by reformulating the query.

**Main Processes:**
- LLM generates multiple semantic variations of the query
- Retrieve chunks for each variation
- Collect all retrieved results

**Output:**
```
One Query â†’ Many Reformulated Queries â†’ Many Retrieved Results
```

---

## ğŸ“‚ 9. `multi_query_rrf_retrieval.py` â€” Fusion & Ranking (RRF)

**Purpose:**  
Fuse multiple retrieval result lists into a single better-ranked list.

**Main Processes:**
- Apply Reciprocal Rank Fusion scoring
- Boost documents appearing across multiple lists
- Sort by final fused score

**Output:**
```
Multiple Rankings â†’ Fused Final Ranking
```

---

# ğŸ§© Overall RAG Flow (All Files Together)

```
(1) ingestion_pipeline.py
          â†“
(2) retrieval_pipeline.py
          â†“
(3) answer_generation.py
          â†“
(4) chat_pipeline.py (optional multi-turn)
          â†“
(5) multi_query + RRF (optional optimization)
```

---

# ğŸ One-Line Summaries

| File | Summary |
|---|---|
| ingestion_pipeline | Prepare docs for search |
| retrieval_pipeline | Find relevant chunks |
| answer_generation | Answer using retrieved data |
| chat_pipeline | Multi-turn conversational RAG |
| chunking_methods | Size-based splitting |
| semantic_chunking | Meaning-based splitting |
| agentic_chunking | LLM-driven splitting |
| multi_query_retrieval | Query reformulation for recall |
| multi_query_rrf_retrieval | Fusion for better ranking |

---
